{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_NDu2DUeZIV",
        "outputId": "d8e6559b-19d5-4f1b-96ec-282f2106175d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_combined_inference.py\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# ==============================================================================\n",
        "# --- 1. SETUP: INSTALL DEPENDENCIES ---\n",
        "# ==============================================================================\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"Checks for and installs required Python packages.\"\"\"\n",
        "    print(\"--- Checking and installing required packages ---\")\n",
        "    # Add all packages your models depend on.\n",
        "    required_packages = ['pandas', 'numpy', 'scipy', 'tqdm', 'joblib', 'catboost', 'mne', 'scikit-learn']\n",
        "    for package in required_packages:\n",
        "        try:\n",
        "            __import__(package)\n",
        "        except ImportError:\n",
        "            print(f\"Installing {package}...\")\n",
        "            # Use -q for a quieter installation\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "    print(\"--- All packages are ready ---\")\n",
        "\n",
        "# Execute the installation check before doing anything else.\n",
        "install_packages()\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# --- 2. MAIN SCRIPT LOGIC (AFTER INSTALLATION) ---\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import time\n",
        "import warnings\n",
        "from scipy.signal import butter, filtfilt, welch\n",
        "from tqdm import tqdm\n",
        "from catboost import CatBoostClassifier\n",
        "from mne.decoding import CSP\n",
        "\n",
        "# --- Configuration ---\n",
        "# These paths are set up for a typical Google Drive structure.\n",
        "# Adjust them if your folder layout is different.\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/aic3'\n",
        "RAW_DATA_PATH = os.path.join(DRIVE_BASE_PATH, 'unzipped')\n",
        "ARTIFACTS_BASE_PATH = '/content/drive/MyDrive/aic3/ssvep_model_artifacts'\n",
        "MI_ARTIFACTS_PATH = os.path.join(DRIVE_BASE_PATH, 'MI')\n",
        "SSVEP_ARTIFACTS_PATH = os.path.join(ARTIFACTS_BASE_PATH)\n",
        "\n",
        "SUBMISSION_FILE_PATH = os.path.join(DRIVE_BASE_PATH, 'combined_submission.csv')\n",
        "TEST_CSV_PATH = os.path.join(RAW_DATA_PATH, 'test.csv')\n",
        "\n",
        "# --- MI Task Constants ---\n",
        "MI_CHANNELS = ['C3', 'CZ', 'C4']\n",
        "MI_TRIAL_SAMPLES = 2250\n",
        "\n",
        "# --- SSVEP Task Constants ---\n",
        "SSVEP_CHANNELS = ['PO7', 'PZ', 'OZ', 'PO8']\n",
        "SSVEP_SAMPLING_RATE = 250\n",
        "SSVEP_TRIAL_DURATION = 7.0\n",
        "SSVEP_TRIM_START_S = 1.0\n",
        "SSVEP_TARGET_FREQS = [7, 8, 10, 13]\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==============================================================================\n",
        "# --- MOTOR IMAGERY (MI) HELPER FUNCTIONS ---\n",
        "# ==============================================================================\n",
        "\n",
        "def load_mi_test_trial(row, base_path):\n",
        "    path = os.path.join(base_path, 'MI', 'test', row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
        "    eeg_data = pd.read_csv(path)\n",
        "    start_idx = (int(row['trial']) - 1) * MI_TRIAL_SAMPLES\n",
        "    end_idx = start_idx + MI_TRIAL_SAMPLES\n",
        "    return eeg_data.iloc[start_idx:end_idx][MI_CHANNELS].values\n",
        "\n",
        "def mi_normalize_trial(trial_data):\n",
        "    mean = trial_data.mean(axis=0, keepdims=True)\n",
        "    std = trial_data.std(axis=0, keepdims=True)\n",
        "    return (trial_data - mean) / (std + 1e-8)\n",
        "\n",
        "def mi_bandpass_filter(data, low=8, high=30, fs=250, order=4):\n",
        "    nyquist = 0.5 * fs\n",
        "    b, a = butter(order, [low / nyquist, high / nyquist], btype='band')\n",
        "    return filtfilt(b, a, data, axis=0)\n",
        "\n",
        "def mi_apply_subject_norm(trial_data, subject_id, subject_stats):\n",
        "    stats = subject_stats['subjects'].get(subject_id, subject_stats['global'])\n",
        "    return (trial_data - stats['mean']) / (stats['std'] + 1e-8)\n",
        "\n",
        "def mi_compute_psd(trial, fs=250, bands=[(0.5,4), (4,8), (8,13), (13,30), (30,50)]):\n",
        "    features = []\n",
        "    for ch in range(trial.shape[1]):\n",
        "        f, Pxx = welch(trial[:, ch], fs=fs, nperseg=256)\n",
        "        for band in bands:\n",
        "            fmin, fmax = band\n",
        "            features.append(np.trapz(Pxx[(f >= fmin) & (f <= fmax)], f[(f >= fmin) & (f <= fmax)]))\n",
        "    return np.array(features)\n",
        "\n",
        "def predict_mi_trial(row, artifacts, base_data_path):\n",
        "    trial_data = load_mi_test_trial(row, base_data_path)\n",
        "    normalized_data = mi_normalize_trial(trial_data)\n",
        "    filtered_data = mi_bandpass_filter(normalized_data)\n",
        "    final_preprocessed_data = mi_apply_subject_norm(filtered_data, row['subject_id'], artifacts['stats'])\n",
        "    csp_input = final_preprocessed_data.T.reshape(1, len(MI_CHANNELS), MI_TRIAL_SAMPLES)\n",
        "    csp_features = artifacts['csp'].transform(csp_input)\n",
        "    psd_features = mi_compute_psd(final_preprocessed_data).reshape(1, -1)\n",
        "    combined_features = np.hstack([csp_features, psd_features])\n",
        "    prediction_encoded = artifacts['model'].predict(combined_features)\n",
        "    return 'Left' if int(prediction_encoded[0]) == 0 else 'Right'\n",
        "\n",
        "# ==============================================================================\n",
        "# --- SSVEP HELPER FUNCTIONS ---\n",
        "# ==============================================================================\n",
        "\n",
        "def load_ssvep_test_trial(row, base_path):\n",
        "    path = os.path.join(base_path, 'SSVEP', 'test', row['subject_id'], str(row['trial_session']), 'EEGdata.csv')\n",
        "    eeg_data = pd.read_csv(path).ffill().bfill()\n",
        "    samples_per_trial = int(SSVEP_TRIAL_DURATION * SSVEP_SAMPLING_RATE)\n",
        "    trim_samples = int(SSVEP_TRIM_START_S * SSVEP_SAMPLING_RATE)\n",
        "    start_idx = (int(row['trial']) - 1) * samples_per_trial\n",
        "    return eeg_data.iloc[start_idx + trim_samples : start_idx + samples_per_trial][SSVEP_CHANNELS].values\n",
        "\n",
        "def ssvep_bandpass_filter(data):\n",
        "    low, high, order = 4.0, 42.0, 4\n",
        "    nyq = 0.5 * SSVEP_SAMPLING_RATE\n",
        "    b, a = butter(order, [low / nyq, high / nyq], btype='band')\n",
        "    return np.apply_along_axis(lambda x: filtfilt(b, a, x), 0, data)\n",
        "\n",
        "def ssvep_get_psd_features(data):\n",
        "    all_features = []\n",
        "    nperseg = SSVEP_SAMPLING_RATE * 4\n",
        "    for i in range(data.shape[1]):\n",
        "        freqs, psd = welch(data[:, i], fs=SSVEP_SAMPLING_RATE, nperseg=nperseg, nfft=nperseg * 2)\n",
        "        for f in SSVEP_TARGET_FREQS:\n",
        "            for h in range(1, 4):\n",
        "                harmonic_freq = h * f\n",
        "                target_idx = np.argmin(np.abs(freqs - harmonic_freq))\n",
        "                noise_indices = np.where((freqs >= harmonic_freq - 3) & (freqs <= harmonic_freq + 3) & (np.abs(freqs - harmonic_freq) > 0.25))[0]\n",
        "                signal_power = psd[target_idx]\n",
        "                noise_power = np.mean(psd[noise_indices]) if len(noise_indices) > 0 else 1e-12\n",
        "                all_features.extend([signal_power, signal_power / noise_power])\n",
        "    return np.array(all_features)\n",
        "\n",
        "def predict_ssvep_trial(row, artifacts, base_data_path):\n",
        "    eeg_signals = load_ssvep_test_trial(row, base_data_path)\n",
        "    filtered_signals = ssvep_bandpass_filter(eeg_signals)\n",
        "    features = ssvep_get_psd_features(filtered_signals).reshape(1, -1)\n",
        "    scaled_features = artifacts['scaler'].transform(features)\n",
        "    selected_features = artifacts['selector'].transform(scaled_features)\n",
        "    prediction_encoded = artifacts['model'].predict(selected_features)\n",
        "    return artifacts['le'].inverse_transform(prediction_encoded)[0]\n",
        "\n",
        "# ==============================================================================\n",
        "# --- MAIN INFERENCE ORCHESTRATOR ---\n",
        "# ==============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to load all artifacts and run inference for all tasks.\"\"\"\n",
        "    print(\"--- [1/5] Starting COMBINED INFERENCE Pipeline ---\")\n",
        "\n",
        "    # --- Load MI Artifacts ---\n",
        "    print(f\"--- [2/5] Loading MI artifacts from: {MI_ARTIFACTS_PATH} ---\")\n",
        "    try:\n",
        "        mi_artifacts = {\n",
        "            'model': joblib.load(os.path.join(MI_ARTIFACTS_PATH, 'catboost_mi_model.pkl')),\n",
        "            'csp': joblib.load(os.path.join(MI_ARTIFACTS_PATH, 'csp_mi_transformer.pkl')),\n",
        "            'stats': joblib.load(os.path.join(MI_ARTIFACTS_PATH, 'mi_subject_stats.pkl'))\n",
        "        }\n",
        "        print(\"MI artifacts loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"FATAL ERROR: Could not load MI artifacts. {e}\\nCheck that the path is correct and the files exist.\")\n",
        "        return\n",
        "\n",
        "    # --- Load SSVEP Artifacts ---\n",
        "    print(f\"--- [3/5] Loading SSVEP artifacts from: {SSVEP_ARTIFACTS_PATH} ---\")\n",
        "    try:\n",
        "        ssvep_artifacts = {\n",
        "            'model': joblib.load(os.path.join(SSVEP_ARTIFACTS_PATH, 'ssvep_model.joblib')),\n",
        "            'scaler': joblib.load(os.path.join(SSVEP_ARTIFACTS_PATH, 'ssvep_scaler.joblib')),\n",
        "            'selector': joblib.load(os.path.join(SSVEP_ARTIFACTS_PATH, 'ssvep_selector.joblib')),\n",
        "            'le': joblib.load(os.path.join(SSVEP_ARTIFACTS_PATH, 'ssvep_label_encoder.joblib'))\n",
        "        }\n",
        "        print(\"SSVEP artifacts loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"FATAL ERROR: Could not load SSVEP artifacts. {e}\\nCheck that the path is correct and the files exist.\")\n",
        "        return\n",
        "\n",
        "    # --- Load Test Metadata ---\n",
        "    print(f\"--- [4/5] Loading test metadata from: {TEST_CSV_PATH} ---\")\n",
        "    if not os.path.exists(TEST_CSV_PATH):\n",
        "        print(f\"FATAL ERROR: Test metadata file not found at {TEST_CSV_PATH}\")\n",
        "        return\n",
        "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
        "    print(f\"Found {len(test_df)} total test samples.\")\n",
        "\n",
        "    # --- Main Prediction Loop ---\n",
        "    print(\"--- [5/5] Generating predictions for all tasks ---\")\n",
        "    results = []\n",
        "    prediction_start_time = time.time()\n",
        "\n",
        "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Predicting All Tasks\"):\n",
        "        try:\n",
        "            if row['task'] == 'MI':\n",
        "                label = predict_mi_trial(row, mi_artifacts, RAW_DATA_PATH)\n",
        "            elif row['task'] == 'SSVEP':\n",
        "                label = predict_ssvep_trial(row, ssvep_artifacts, RAW_DATA_PATH)\n",
        "            else:\n",
        "                label = \"Error_Unknown_Task\"\n",
        "            results.append({'id': row['id'], 'label': label})\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing trial ID {row['id']} (Task: {row['task']}): {e}\")\n",
        "            results.append({'id': row['id'], 'label': 'Error_Processing_Failed'})\n",
        "\n",
        "    prediction_end_time = time.time()\n",
        "\n",
        "    # --- Final Step: Save Submission and Report Timings ---\n",
        "    submission_df = pd.DataFrame(results).sort_values(by='id').reset_index(drop=True)\n",
        "    submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n",
        "\n",
        "    total_prediction_time = prediction_end_time - prediction_start_time\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"      COMBINED INFERENCE COMPLETE\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total time for prediction loop: {total_prediction_time:.2f} seconds\")\n",
        "    print(f\"Average time per sample: {total_prediction_time / len(test_df):.4f} seconds\")\n",
        "    print(f\"\\nFinal submission file saved to: {SUBMISSION_FILE_PATH}\")\n",
        "    print(\"\\nSubmission Head:\")\n",
        "    print(submission_df.head())\n",
        "    print(\"\\nSubmission Tail:\")\n",
        "    print(submission_df.tail())\n",
        "    print(\"=\"*50)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH9hMW6lehIo",
        "outputId": "8ed1fc13-b60d-4c3a-e063-9a2df30f1d5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_combined_inference.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In a notebook cell\n",
        "!python run_combined_inference.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhrmQQ8ve91i",
        "outputId": "acf9fece-0713-40a3-9a00-65624384e410"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Checking and installing required packages ---\n",
            "Installing scikit-learn...\n",
            "--- All packages are ready ---\n",
            "--- [1/5] Starting COMBINED INFERENCE Pipeline ---\n",
            "--- [2/5] Loading MI artifacts from: /content/drive/MyDrive/aic3/MI ---\n",
            "MI artifacts loaded successfully.\n",
            "--- [3/5] Loading SSVEP artifacts from: /content/drive/MyDrive/aic3/ssvep_model_artifacts ---\n",
            "SSVEP artifacts loaded successfully.\n",
            "--- [4/5] Loading test metadata from: /content/drive/MyDrive/aic3/unzipped/test.csv ---\n",
            "Found 100 total test samples.\n",
            "--- [5/5] Generating predictions for all tasks ---\n",
            "Predicting All Tasks: 100% 100/100 [00:26<00:00,  3.82it/s]\n",
            "\n",
            "==================================================\n",
            "      COMBINED INFERENCE COMPLETE\n",
            "==================================================\n",
            "Total time for prediction loop: 26.17 seconds\n",
            "Average time per sample: 0.2617 seconds\n",
            "\n",
            "Final submission file saved to: /content/drive/MyDrive/aic3/combined_submission.csv\n",
            "\n",
            "Submission Head:\n",
            "     id label\n",
            "0  4901  Left\n",
            "1  4902  Left\n",
            "2  4903  Left\n",
            "3  4904  Left\n",
            "4  4905  Left\n",
            "\n",
            "Submission Tail:\n",
            "      id     label\n",
            "95  4996     Right\n",
            "96  4997   Forward\n",
            "97  4998     Right\n",
            "98  4999  Backward\n",
            "99  5000   Forward\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jpsvc_RgfIMT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}